---
title: "08  A Rapid Introduction to th R Language - Bioinformatics Data Skills - O'Reilly"
author: "Charles Drummer IV"
date: "3/31/2022"
output: html_document
---

“Part III. Practice: Bioinformatics Data Skills”

Excerpt From
Bioinformatics Data Skills
Vince Buffalo
https://books.apple.com/us/book/bioinformatics-data-skills/id1025338879
This material may be protected by copyright.

“Chapter 8. A Rapid Introduction to the R Language”

Excerpt From
Bioinformatics Data Skills
Vince Buffalo
https://books.apple.com/us/book/bioinformatics-data-skills/id1025338879
This material may be protected by copyright.

R language is a data programming language yo ucan use to explore and  understand data in an  open-ended, highly interactive, iterative way

R language allows for *exploratory data analysis (EDA)* 
- EDA is an approach emphasizing understanding data and data limitations though interactive investigation rather tha n explicit statistical modeling

EDA can  reveal patterns in bioinformatics data overlooked with statistical modeling or hypothesis testing approaches

Chapter goal: teach EDA skills to give the freedom to explore and experiment with your data at any stage of analysis

# Getting started with R and RStudio
RStudio has a "Console" and a "Terminal" shell.  While R can be run in the Console, installing R in the terminal first allows for running R code in-line in the coding window
```{installing R in terminal}
$ brew install r
```
Developing code in R is back-and-forth between
- writing code in a re-runnable script
- exploring data interactively in the R interpreter

The comprehensive R archive network (CRAN) is a collection of packages that extend R's functionality
- packages can be installed directly within R with 'install.packages()' function
```{installing ggplot2 with install.packages function in R}
# 
> install.packages("ggplot2")
```
# R language basics

## Simple calculations in R, calling functions and getting help in R
expression - a calculation or command enter into an R console
evaluated expression - a result printed to console after pressing 'enter'

Arithmetic operations follow basic order of operations; parenthesis often needed to indicate order of operations 
```{white space and order of operations}
> 3 + 4/2
[1] 5
> (3 + 4)/2
[1] 3.5
```
Functions can be used to perform mathematics operations
- functions take zero or more arguments, perform calculations and output a return value 
- R functions copy arguments, do not modify arguments in place 

Common mathematics functions in  R
- exp(x): Exponential function [Example: exp(1), exp(2)]
- log(x, base=exp(1)), log10(), log2(): Natural, base 10, and base 2 logarithms [Example: log(2), log10(100), log2(16)}
- sqrt(x): Square root [Example: sqrt(2)]
- sin(x), cos(x), tan(x), etc.: Trigonometric functions (see help(sin) for more) [Example: sin(pi)]
- abs(x): Absolute value [Example: abs(-3)]
- factorial(x): Factorial [Example: factorial(5)]
- choose(n, k): Binomial coefficient [Example: choose(5, 3)]
Note: Significant digits
- R prints 7 signifcant digits by default
- 'print()' function can be used to change sig fig
```{mathematic functions and sig figs}
# square root function
>  sqrt(3.5)

# squart root function with 10 sig fig
> print(sqrt(3.5), digits = 10)
```
Returned values can ether be saved as variable or passed directly to another function as an argument 
```{passing sqrt function into round function as  argument}
# passing sqrt function returned value into the round function
> round(sqrt(3.5))
[1] 2

# round to a specific decimal place by adding digit argument
> round(sqrt(3.5), digits=3)
[1] 1.871
> round(sqrt(3.5), 3)
[1] 1.871
```
## Variables and assignment
variable - a character or string that holds a value, assigned using '<-' assignment operator (Note: '=' can also be used to assign value to variable)
```{Assign value to variable x}
# assign value to variable x
> x <- 3.1

# retrieve value by entering variable into console
> x
3.1

# variables can be used in mathematics  expressions 
> (x + 2)/2
[1] 2.55
> exp(x)
[1] 22.1979513
> y <- exp(2*x) - 1
> y
[1] 491.749041
```
Values set to variables are assigned to an *environment* know the *global environment*
'ls()' function prints all asigned variable in global environment
```{print variables in environment}
> ls()
[1] "x"
```
# Vectors, vectorization and indexing
- *vector* - a container of contiguous data
  - vector of length 1 holds a single value
  - 'length()' function returns the length of a vector
```{vector length}
> length(3.1)
```
  - create longer vectors with 'c()' function
```{creating vector and storing in variable}
> x <- c(56, 95.3, 0.4)
> x
[1] 56.0 95.3  0.4
> y <- c(3.2, 1.1, 0.2)
> y
[1] 3.2 1.1 0.2
```
  - vectors can contain both variable-value pairs
```{vectors with values and variable  pairs}
> b <- c(a=3.4, b=5.4, c=0.4)
> b
  a   b   c
3.4 5.4 0.4

# variables can be called from vector
> names(b)
[1] "a" "b" "c"


```
- *vectorization* - process allowing for loop over vectors elementwise without needing to write an explicit loop
```{Vectorization and variable operations}
# store vector in x
 > x <- c(56, 95.3, 0.4)

# store vector in  y
> y <- c(3.2, 1.1, 0.2)

# Operations based on  values in corresponding vector positions in x and y
> x + y
[1] 59.2 96.4  0.6
> x - y
[1] 52.8 94.2  0.2
> x/y
[1] 17.50000 86.63636  2.00000

```
integer sequences function 'seq()' prints sequence between arguments
```{Seq function}
> seq(3, 5)
[1] 3 4 5
> 1:5
[1] 1 2 3 4 5
```
- *recycling* - vector operations performed when one vector is shorter than  the other, shorter vector applied  
-  allows for the addition  of a single value  to all elements in a  longer vector
```{Recycling vector operations}
> x
[1] 56.0 95.3  0.4
> x - 3
[1] 53.0 92.3 -2.6
> x / 2
[1] 28.00 47.65  0.20
> sqrt(x)
[1] 7.4833148 9.7621719 0.6324555
> round(sqrt(x), 3)
[1] 7.483 9.762 0.632
> log(x)/2 + 1 # note how we can combined vectorized operations
[1] 3.0126758 3.2785149 0.5418546
```
- recycling requires smaller group to be a multiple of the larget one
```{recylcing vectors with non-multiple vectors}
> c(1, 2) + c(0, 0, 0, 0) 
[1] 1 2 1 2
> c(1, 2) + c(0, 0, 0) 
[1] 1 2 1
Warning message:
In c(1, 2) + c(0, 0, 0) :
  longer object length is not a multiple of shorter object length
```
- *indexing* - accessing specific elements of a vector; an index is the integer that specifies  which element in the vector to retrieve
```{retrieving indexed vector elements}
# retrieving indexes from a vector
> x <- c(56, 95.3, 0.4)
> x[2] 
[1] 95.3
> x[1]
[1] 56
> x[4] 
[1] NA

# resigning an index in a vector
> x[3] <- 0.5 
> x
[1] 56.0 95.3  0.5

# names can be reset in place
> names(b) <- c("x", "y", "z")
> b
  x   y   z
3.4 5.4 0.4

# value-variable pairs can be retrieve from index
> b['x']
  x
3.4
> b['z']
  z
0.4
```
Vectors can be written to include certain values only or to exclude certain values
```{including or excluding values in a vector}
# extract indices 3-5 from vector z
> z <- c(3.4, 2.2, 0.4, -0.4, 1.2)
> z[3:5] # extract third, fourth, and fifth elements
[1]  0.4 -0.4  1.2

# exclude indices 4 and 5 from vector z
> z[c(-4, -5)]   # exclude fourth and fifth elements
[1] 3.4 2.2 0.4
```
Vectors can be reorganized based on indice number
# reorder indices in vector z
> z[c(3, 2, 4, 5, 1)]
[1]  0.4  2.2 -0.4  1.2  3.4


# reverse order in vector z
> z[5:1]
[1]  1.2 -0.4  0.4  2.2  3.4

# reordering using 'order()' function
> order(z)
[1] 4 3 5 2 1
> z[order(z)]
[1] -0.4  0.4  1.2  2.2  3.4
> order(z, decreasing=TRUE)
[1] 1 2 5 3 4
> z[order(z, decreasing=TRUE)]
[1]  3.4  2.2  1.2  0.4 -0.4
```

Comparison operators ('==', '!=', '<', '<=', '>', '>=') can be used to build *logical vectors*

R's comparison and logical operators
- >: Greater than
- <: Less than
- >=: Greater than or equal to
- <=: Less than or equal to
- ==: Equal to
- !: Not equal to
- &: Elementwise logical AND
- |: Elementwise logical OR
- !: Elementwise logical NOT
- &&: Logical AND (first element only, for if statements)
- ||: Logical OR (first element only, for if statements)

```{building logical vectors}
# building logical vectors based on comparison operators
> v <- c(2.3, 6, -3, 3.8, 2, -1.1)
> v == 6
[1] FALSE  TRUE FALSE FALSE FALSE FALSE
> v <= -3
[1] FALSE FALSE  TRUE FALSE FALSE FALSE
> abs(v) > 5
[1] FALSE  TRUE FALSE FALSE FALSE FALSE

# creating subsets or larger vector based on comparison operators
> v[v > 2]
[1] 2.3 6.0 3.8
```

## Vector types
Vectors in R must contain elements of the same type.  Supported data types:
- Numeric (double vectors): includes real numbhers
- Integers: whole numbers, positive or negative
- Characters: strings in quotations
- Logical: TRUE or FALSE
- Complex: complex (imaginary) numbers
- Raw: encodes raw bytes

R will coerce values based on coercion rules to ensure all elements in a vector are the same type
```{check the type of any object}
> q <- c(2, 3.5, -1.1, 3.8)
> typeof(q)
[1] "double”
```
- logical values coerced into 0 or 1
```{logical to numeric coercion}
> c(4.3, TRUE, 2.1, FALSE)
[1] 4.3 1.0 2.1 0.0
```
- interger values coerced into numeric
```{interger to numeric coercion}
# 'L' tag specifies a nmber as an integer
> c(-9L, 3.4, 1.2, 3L)
[1] -9.0  3.4  1.2  3.0
```
- if any value is a string, all values converted to string
```{string coercion}
> c(43L, TRUE, 3.2413341, "a string")
[1] "43"        "TRUE"      "3.2413341" "a string"
```

## Factors and classes in R

### Factors
factor - a kind of vector storing categorical variables (treatment, strand, chromosome etc)

Vectors can be convered to using 'factor()' function
- 'factor()' function also outputs "levels" which are the total values for the categorical variable
```{converting vectors to factors}
> chr_hits <- c("chr2", "chr2", "chr3", "chrX", "chr2", "chr3", "chr3")
> hits <- factor(chr_hits)
# "printing" a factor gives the vector values and the total levels
> hits
[1] chr2 chr2 chr3 chrX chr2 chr3 chr3
Levels: chr2 chr3 chrX

# 'levels()' function gives just the levels for a factor
> levels(hits)
[1] "chr2" "chr3" "chrX"
```

All possible levels can be specified (in situations where some values may not be present but you want them to be saved as possible values)
``` {defining levels}
> hits <- factor(chr_hits, levels=c("chrX", "chrY", "chr2", "chr3", "chr4"))
> hits
[1] chr2 chr2 chr3 chrX chr2 chr3 chr3
Levels: chrX chrY chr2 chr3 chr4
```
Existing levels in a factor can be renamed with 'levels()' 
```{renaming levels using 'list' function}
# 'hits' is already defined as a factor, we want to reset the possible levels using 'list'
> levels(hits) <- list(chrX="chrX", chrY="chrY", chr2="chr2",
                       chr3="chr3", chr4="chr4")
> hits
[1] chr2 chr2 chr3 chrX chr2 chr3 chr3
Levels: chrX chrY chr2 chr3 chr4
```

### Classes
class - endows an objecct with higher-level proterties that can affect how functions treat that object in R
- Factors are simply integers assigned a level variable name
```{assessing factor as integer values}
> typeof(hits)
[1] "integer"
> as.integer(hits)
[1] 3 3 4 1 3 4 4
```

Generic (*polymorphic*) functions  work on objects of all classes
- 'table()' is a generic function.  Total number of each level can be determined using 'table()' function
```{counting level in a factor}
> table(hits)
hits
chrX chrY chr2 chr3 chr4
   1    0    3    3    0
```
- 'summary()' is a genreic function that summarizes an object (i.e. vector) but its output depends on the class of values in the object
```{summary function output for numeric vs factor values}
> nums <- c(0.97, -0.7, 0.44, 0.25, -1.38, 0.08)
# summary function on "numeric" class data
> summary(nums)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
-1.38000 -0.50500  0.16500 -0.05667  0.39250  0.97000
# summary function on "factor" class data
> summary(hits)
chrX chrY chr2 chr3 chr4
   1    0    3    3    0
```

# Working with and visualizing data in R
[Tutorial using data from "The Influence of Recombination on Human Genetic Diversity]<http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0020148>.

## Loading Data into R
Note: in some cases, you may need to use unix tools to reformat data into tab-delimited format, use 'hexdump' to remove non-ASCII characters in files or coerce columns/remove improper values with R

*working directories* - the current working folder/directory in R; R defaults to home directory. 
- 'getwd()' function shows working directory
```{get working directory in r}
> getwd()
```
- 'setwd()' function changes directory 
```{change working directory in r}
> setwd ("~/bds-files-master/chapter-08-r")
```
Before load data into R, in the terminal use 'head' or 'cat' to review file structure (comments present, column delimits etc.)

r command for loading tables is 'read.table()'
- Note: 'read.table()' functions reformat some headers.  
	- 'spaces' are replaced with '
	- '%' are chanted to 'X'
- 'read.csv()' and 'read.delim()' are version of 'read.table()'
- large strings representing file names can be stored as variables in r to avoid repeat typing
```{loading dataset and storing as variable}
> d <- read.csv("Dataset_S1.txt")
```
- 'read.table()' and its other forms have a 'header' argument.  If a table starts with the names of the column the header will be 'TRUE'.  If the file does not contain headers, they van be assigned usig the 'col.names' argument (creads a vector wit hteh column names)
```{assigning column headers if not present in file}
> bd <- read.delim("noheader.bed", header=FALSE,
                   col.names=c("chrom", "start", "end"))
```
- by default, 'R encodes categorical 'read.delim()' and 'read.csv()' coerce column strings to a factor.  If you require to be a character vector instead set the argument 'stringsAsFactors=FALSE'

Table 8-4. Commonly used read.csv() and read.delim() arguments
Argument	Description	Additional comments
header
A TRUE/FALSE value indicating whether the first row contains column names rather than data
sep
A character value indicating what delimits columns; using the empty string "" treats all whitespace as a separator
stringsAsFactors
Setting this argument as FALSE prevents R from coercing character vectors to factors for all columns; see argument asis in help(read.delim) to prevent coercion to factor on specific columns
This is an important argument to be aware of, because R’s default behavior of coercing character vector columns to factors is a common stumbling block for beginners.
col.names
A character vector to be used as column names

row.names
A vector to use for row names, or a single integer or column name indicating which column to use as row names
na.strings
A character vector of possible missing values to convert to NA
Files using inconsistent missing values (e.g., a mix of “NA,” “Na,” “na”) can be corrected using na.strings=c("NA", "Na", "na").
colClasses
A character vector of column classes; "NULL" indicates a column should be skipped and NA indicates R should infer the type
colClasses can drastically decrease the time it takes to load a file into R, and is a useful argument when working with large bioinformatics files.
comment.char
Lines beginning with this argument are ignored; the empty string (i.e., "") disables this feature
This argument is useful in ignoring metadata lines in bioinformatics files.

## Long vs Wide Data
*wide data* - each variable has its own column, each row is for a new/single sample (normally how humans record data)
*long data* - one column is used to store what type of variable was measured and another is used to store the measurement
'reshape2' package provides functions to reshpate data
- 'melt()' function - turns wide into long data
- 'cast()' - turns long into wide data

## Exploring and transforming dataframes
*dataframe* - an R element consisting of columns (representing variables in your dataset) and rows (representiong observations); designed to hold columns of heterogeneous types of vectors

dataframe columns are vectors with each element being of the same type; different columns can be of differnt types 

'head()' function loads adn previews a dataframe
- defaults to showing 6 lines, can be changed with the 'n=<number>' argument
```{previewing with head function}
> head(d, n=3)
```

Dimensions of a dataframe can be evaluated using:
- 'nrow()' - number of rows
- 'ncol()' - number of columns
- 'dim()' - number of rows and columns 
- 'colnames()' - prints the column headers
- 'rownames()' - pritns the row headers
- converted column headers can be renamed to be more descriptive
```{renaming headers using column name function}
# specify the column to change by putting its position in '[]'
> colnames(d)[12] # original name
[1] "X.GC"
> colnames(d)[12] <- "percent.GC"
> colnames(d)[12] # after change
[1] "percent.GC"
```
- row names can be renamed as well (rows must have unique names)
- '$' operator can specify the column name and print that column as a vector.  This can be used to perform statistics on that column values
```{dollar sign operator to print column}
> d$depth
  [1]  3.41  6.68  9.06 10.26  8.06  7.05 [...]
# using column print to calculate average
“> mean(d$depth)
[1] 8.183938
> summary(d$depth)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  1.000   6.970   8.170   8.184   9.400  21.910
```
- data frame indexing finds data using two indexes. General syntax:  '<dataframe_variable>[row, col]'
	- Omitting the 'row' index returns all rows for the specified columns
```{return all rows in columns 1 and 2}
# retrieving two columns using column index
> d[ , 1:2]
  start   end
1 55001 56000
2 56001 57000
3 57001 58000
[...]
# retrieving two columns using a vector containing the column headers
> d[, c("start", "end")]
  start   end
1 55001 56000
2 56001 57000
3 57001 58000
[...]
# retrieve the first row
> d[1, ]
  start   end total.SNPs total.Bases depth unique.SNPs dhSNPs reference.Bases
1 55001 56000          0        1894  3.41           0      0             556
  Theta Pi Heterozygosity percent.GC Recombination  Divergence Constraint SNPs
1     0  0              0    54.8096   0.009601574 0.003006012          0    0
# retrieving a single cell
> d[2,3]
[1] 5
```
	- retrieiving a *single* column from a dataframe returns a *vector* by default.  To preserve dataframe class, use 'drop' option
```{retrieving single column and retaining dataframe class}
> d[, "start", drop=FALSE]
  start
1 55001
2 56001
3 57001
[...]
```

Columns can be added to dataframe
```{adding column to dataframe}
# adding column to represent a window in the centromere region
# dollar operator used to specify a column, for centromire window.  Ampersand is the vector logical operator for AND
> d$cent <- d$start >= 25800000 & d$end <= 29700000
# summarize information with 'table' function
> table(d$cent)
FALSE  TRUE
58455   685
# operations can be performed and stored in new columns
> d$diversity <- d$Pi / (10*1000)  # rescale, removing 10x and making per bp
> summary(d$diversity )
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
0.0000000 0.0005577 0.0010420 0.0012390 0.0016880 0.0265300
```

## Exploring Data through slicing and dicing: subsetting dataframes
*Dataframe subsetting* - specifying a portion of a data frame using R comparisons and logical operators

Exploring skewed data is a use of subsetting
```{exploring skewed data using subsetting}
# data thats skewed right and subset for values with 55 or moer SNPs
> summary(d$total.SNPs)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  0.000   3.000   7.000   8.906  12.000  93.000
# creating a logical vector for values in our dersired rand
> d$total.SNPs >= 85
[1] FALSE FALSE FALSE FALSE FALSE FALSE [...]
# creating a subset extracting rows from the data frame and saving in new dataframe
> d[d$total.SNPs >= 85, ]
         start      end total.SNPs total.Bases depth unique.SNPs dhSNPs
2567   2621001  2622000         93       11337 11.34          13     10
12968 13023001 13024000         88       11784 11.78          11      1
43165 47356001 47357000         87       12505 12.50           9      7
      reference.Bases  Theta     Pi Heterozygosity percent.GC Recombination
2567             1000 43.420 50.926         81.589    43.9439   0.000706536
12968            1000 33.413 19.030         74.838    28.8288   0.000082600
43165            1000 29.621 27.108         69.573    46.7467   0.000500577
      Divergence Constraint SNPs  cent
2567  0.01701702          0    1 FALSE
12968 0.01401401          0    1 FALSE
43165 0.02002002          0    7 FALSE
```

subsetting can increase in complexity by chaining comparision operators in queries
```{compound variables for subsetting queries}
> d[d$Pi > 16 & d$percent.GC > 80, ]
         start      end total.SNPs total.Bases depth unique.SNPs dhSNPs
58550 63097001 63098000          5         947  2.39           2      1
58641 63188001 63189000          2        1623  3.21           2      0
58642 63189001 63190000          5        1395  1.89           3      2
      reference.Bases  Theta     Pi Heterozygosity percent.GC Recombination
58550             397 37.544 41.172         52.784    82.0821   0.000781326
58641             506 16.436 16.436         12.327    82.3824   0.000347382
58642             738 35.052 41.099         35.842    80.5806   0.000347382
      Divergence Constraint SNPs  cent
58550 0.03826531        226    1 FALSE
58641 0.01678657        148    0 FALSE
58642 0.01793722          0    0 FALSE
```

complex queries using logic operators and retrieiving only specific columns
```{complex subsetting returning specific columns}
> d[d$Pi > 16 & d$percent.GC > 80, c("start", "end", "depth", "Pi")]
         start      end depth     Pi
58550 63097001 63098000  2.39 41.172
58641 63188001 63189000  3.21 16.436
58642 63189001 63190000  1.89 41.099
# reordering the select columns
> d[d$Pi > 16 & d$percent.GC > 80, c("start", "end", "Pi", "depth")]
         start      end     Pi depth
58550 63097001 63098000 41.172  2.39
58641 63188001 63189000 16.436  3.21
58642 63189001 63190000 41.099  1.89
# selecting only a vector information from the dataframe matching our logic statement
> d$percent.GC[d$Pi > 16]
[1] 39.1391 38.0380 36.8368 36.7367 43.0430 41.1411 [...]

Subsetting columns to summarize differnt conditions
```{determing if depth varies based on GC content}
> summary(d$depth[d$percent.GC >= 80])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   1.05    1.89    2.14    2.24    2.78    3.37
> summary(d$depth[d$percent.GC < 80])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  1.000   6.970   8.170   8.185   9.400  21.910
```

the negation ('!') operator can be used to subset data that is already logical varibles 
```{using negation operator to subset existing logical data}
> summary(d$Pi[d$cent])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   0.00    7.95   16.08   20.41   27.36  194.40
> summary(d$Pi[!d$cent])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  0.000   5.557  10.370  12.290  16.790 265.300
```

'which()' function returnes all TRUE values from a vector
```{subsetting based on TRUE using which function}
> d$Pi > 3
[1] FALSE  TRUE FALSE  TRUE  TRUE  TRUE [...]
> which(d$Pi > 3)
[1]  2  4  5  6  7 10 [...]
# using which to select first 4 true values in a set
> which(d$Pi > 10)[1:4]
[1]  2 16 21 23

'which.min()' and 'which.max()' functions return the first min/max elements of a vector
> d[which.min(d$total.Bases),]
         start      end total.SNPs total.Bases depth [...]
25689 25785001 25786000          0         110 1.24  [...]

> d[which.max(d$depth),]
       start     end total.SNPs total.Bases depth [...]
8718 8773001 8774000         58       21914 21.91 [...]
```

'subset()' function takes 2-3 arguments: 'subset(<dataframe>,<row_inclusion_conditions>,<column_inclusion_conditions)'
```{subset with 3 arguments}
> subset(d, Pi > 16 & percent.GC > 80,
    c(start, end, Pi, percent.GC, depth))
         start      end     Pi percent.GC depth
58550 63097001 63098000 41.172    82.0821  2.39
58641 63188001 63189000 16.436    82.3824  3.21
58642 63189001 63190000 41.099    80.5806  1.89
```

## Exploring data visually with ggplot2 part I: scatterplots and densities 
Install package
```{installing and loading ggplot2 package}
> install.packages("ggplot2")
> library(ggplot2)
```

'ggplot2' plots build grammaitacally; layers are added to a plot that map the aethetic properties of geometric objects to data.  Layers can:
- apply statistical transformatoins
- change scales, axes and colors

The example data is "windows based", requiring positioning information and midpoint between windows
```{adding position column for window placement}
> d$position <- (d$end + d$start) / 2
> ggplot(d) + geom_point(aes(x=position, y=diversity))
```
